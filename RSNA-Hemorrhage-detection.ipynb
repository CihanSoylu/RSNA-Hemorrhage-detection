{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import glob, pylab\n",
    "import pydicom\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATA_DIR = '../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_12cadc6af_epidural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_12cadc6af_intraparenchymal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_12cadc6af_intraventricular</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_12cadc6af_subarachnoid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_12cadc6af_subdural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID  Label\n",
       "0          ID_12cadc6af_epidural      0\n",
       "1  ID_12cadc6af_intraparenchymal      0\n",
       "2  ID_12cadc6af_intraventricular      0\n",
       "3      ID_12cadc6af_subarachnoid      0\n",
       "4          ID_12cadc6af_subdural      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels for the images in the training data\n",
    "train_df = pd.read_csv(DATA_DIR + 'stage_2_train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train image directory\n",
    "train_img_dir = DATA_DIR + 'stage_2_train/'\n",
    "test_img_dir = DATA_DIR + 'stage_2_test/'\n",
    "train_images = os.listdir(train_img_dir)\n",
    "test_images = os.listdir(test_img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15, 10))\n",
    "columns = 5\n",
    "rows = 4\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = pydicom.read_file(train_img_dir + train_images[i])\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img.pixel_array, cmap=plt.cm.bone)\n",
    "    fig.add_subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICOM format comes with metadata\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new data frame where we have one row for each patient ID and one column per diagnosis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']\n"
     ]
    }
   ],
   "source": [
    "# Get class names\n",
    "CLASS_NAMES = [id.split('_')[2] for id in train_df[:6]['ID'].values]\n",
    "print(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['id'] = train_df['ID'].apply(lambda x: x.split('_')[0] + '_' + x.split('_')[1])\n",
    "train_df['class'] = train_df['ID'].apply(lambda x: x.split('_')[2])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = train_df.drop(columns = ['ID'])\n",
    "new_train_df = new_train_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one row per image ID\n",
    "CLASS_NAMES = np.array(CLASS_NAMES)\n",
    "grouped = new_train_df.groupby(by='id')\n",
    "labels = []\n",
    "ids = []\n",
    "classes = []\n",
    "for name, group in grouped:\n",
    "    #label = [item[0] for item in group.values]\n",
    "    label = list(group['Label'].values)\n",
    "    labels.append(label)\n",
    "    classes.append(''.join(list(CLASS_NAMES[np.array(label) == 1])))\n",
    "    ids.append(name)\n",
    "\n",
    "train_id_df = pd.DataFrame(labels, columns = CLASS_NAMES)\n",
    "train_id_df['ID'] = ids\n",
    "train_id_df['class'] = classes\n",
    "train_id_df = train_id_df.sample(frac=1)\n",
    "train_id_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the new dataframe to csv\n",
    "train_id_df.to_csv('one_hot_labels.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class frequencies\n",
    "grouped_by_class = new_train_df.groupby('class').sum()\n",
    "sns.barplot(y=grouped_by_class.index, x=grouped_by_class.Label, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 8))\n",
    "sns.countplot(x=\"class\", hue=\"Label\", data=new_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are highly imbalanced so we will have to do something about this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windows\n",
    "\n",
    "CT images uses radiodensity instead of gray intesity and the units for the radiodensity is called Hounsfield units (HU). The usual interval for a CT scan is between -1000 and 1000 HUs. If we directly turn this interval into 0-255 units of shade of gray, each unit would correspond to 8 HUs. Human eye can detect about ~16 shades of gray which corresponds to ~130 HUs. Most of the changes due to a hemorrhage happens in an interval of 80-100 HUs, so in order to able to detect these changes we should use a smaller window than -1000 to 1000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_of_dicom_field_as_int(x):\n",
    "    #get x[0] as int if x is a 'pydicom.multival.MultiValue', otherwise get int(x)\n",
    "    if type(x) == pydicom.multival.MultiValue:\n",
    "        return int(x[0])\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "def get_windowing(data):\n",
    "    dicom_fields = [data[('0028','1050')].value, #window center\n",
    "                    data[('0028','1051')].value] #window width\n",
    "    return [get_first_of_dicom_field_as_int(x) for x in dicom_fields]\n",
    "\n",
    "def window_image(dcm, window_center, window_width, correction = True):\n",
    "    if correction:\n",
    "        if (dcm.BitsStored == 12) & (dcm.PixelRepresentation == 0) & (int(dcm.RescaleIntercept) > -100):\n",
    "            correct_dcm(dcm)\n",
    "    \n",
    "    img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n",
    "    img_min = window_center - window_width//2\n",
    "    img_max = window_center + window_width//2\n",
    "    img = np.clip(img, img_min, img_max)\n",
    "    \n",
    "    img = (img - img_min) / (img_max - img_min)\n",
    "                    \n",
    "    return img\n",
    "                    \n",
    "def correct_dcm(dcm):\n",
    "    x = dcm.pixel_array + 1000\n",
    "    px_mode = 4096\n",
    "    x[x >= px_mode] = x[x >= px_mode] - px_mode\n",
    "    dcm.PixelData = x.tobytes()\n",
    "    dcm.RescaleIntercept = -1000\n",
    "\n",
    "\n",
    "def create_window_channels(img_path):\n",
    "    dcm = pydicom.read_file(img_path)\n",
    "    window_center, window_width = get_windowing(dcm)\n",
    "                    \n",
    "    brain_channel = window_image(dcm, 40, 80)\n",
    "    subdural_channel = window_image(dcm, 80, 200)\n",
    "    default_channel = window_image(dcm, window_center, window_width)\n",
    "    \n",
    "    multi_channel = np.array([brain_channel, subdural_channel, default_channel]).transpose(1,2,0)\n",
    "    return multi_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(0,7000, size = 1000)\n",
    "window_centers = []\n",
    "window_widths = []\n",
    "for img_id in np.array(train_images)[random_idx]:\n",
    "    dcm = pydicom.read_file(train_img_dir + img_id)\n",
    "    window_centers += [get_first_of_dicom_field_as_int(dcm[('0028', '1050')].value)]\n",
    "    window_widths += [get_first_of_dicom_field_as_int(dcm[('0028', '1051')].value)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(window_widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(window_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot an example image with the corresponding diagnosis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>any</th>\n",
       "      <th>ID</th>\n",
       "      <th>class</th>\n",
       "      <th>one_hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_327e33972</td>\n",
       "      <td>x</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_cedd11e21</td>\n",
       "      <td>intraventricularany</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_f88929622</td>\n",
       "      <td>x</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_02595b48e</td>\n",
       "      <td>x</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_769385a56</td>\n",
       "      <td>intraventricularany</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epidural  intraparenchymal  intraventricular  subarachnoid  subdural  any  \\\n",
       "0         0                 0                 0             0         0    0   \n",
       "1         0                 0                 1             0         0    1   \n",
       "2         0                 0                 0             0         0    0   \n",
       "3         0                 0                 0             0         0    0   \n",
       "4         0                 0                 1             0         0    1   \n",
       "\n",
       "             ID                class             one_hot  \n",
       "0  ID_327e33972                    x  [0, 0, 0, 0, 0, 0]  \n",
       "1  ID_cedd11e21  intraventricularany  [0, 0, 1, 0, 0, 1]  \n",
       "2  ID_f88929622                    x  [0, 0, 0, 0, 0, 0]  \n",
       "3  ID_02595b48e                    x  [0, 0, 0, 0, 0, 0]  \n",
       "4  ID_769385a56  intraventricularany  [0, 0, 1, 0, 0, 1]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = pd.read_csv(\"../input/rsna-one-hot-labels/one_hot_labels.csv\")\n",
    "ground_truth = ground_truth.fillna('x')\n",
    "ground_truth['one_hot'] = list(ground_truth[CLASS_NAMES].values)\n",
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img_name):\n",
    "    arr = create_window_channels(os.path.join(train_img_dir,img_name + '.dcm'))\n",
    "    channels = ['brain', 'subdural', 'default', 'all']\n",
    "    fig=plt.figure(figsize=(20, 60))\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1,4,i+1)\n",
    "        plt.imshow(arr[:,:,i], cmap=plt.cm.bone)\n",
    "        plt.title(channels[i])\n",
    "    \n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(arr, cmap=plt.cm.bone) \n",
    "    plt.title(channels[3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(train_images[0].split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df, train_idx, valid_idx = train_test_split(ground_truth, ground_truth['class'], stratify = ground_truth['class'], test_size = 0.05, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model():\n",
    "    input_shape = (224,224,3)\n",
    "    base_model = tf.keras.applications.DenseNet201(include_top = False,\n",
    "                                                   weights = 'imagenet',\n",
    "                                                   input_shape = input_shape,\n",
    "                                                   pooling = 'avg')\n",
    "    preprocess = tf.keras.applications.densenet.preprocess_input\n",
    "    \n",
    "    return base_model, preprocess, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value = [value]))\n",
    "\n",
    "def create_example_record(one_hot_label, bottleneck_features):\n",
    "    feature = {'one_hot_label' : _bytes_feature(one_hot_label),\n",
    "              'bottleneck_features' : _bytes_feature(bottleneck_features)}\n",
    "    example = tf.train.Example(features = tf.train.Features(feature = feature))\n",
    "    return example.SerializeToString()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfrecords(df, name = None):\n",
    "    record_dir = 'TFRecords'\n",
    "    \n",
    "    if not os.path.isdir(record_dir):\n",
    "        os.mkdir(record_dir)\n",
    "        \n",
    "    filename = record_dir + '/' + name + '.tfrecords'\n",
    "    writer = tf.io.TFRecordWriter(filename)\n",
    "    count = 0\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        img_path = DATA_DIR + 'stage_2_train/' + row.ID + '.dcm'\n",
    "        try:\n",
    "            img = create_window_channels(img_path)\n",
    "        except:\n",
    "            continue\n",
    "        #img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "        img = tf.image.resize(img, size = (224,224))\n",
    "        img = tf.expand_dims(img, axis = 0)\n",
    "        \n",
    "        img = preprocess(img)\n",
    "        bottleneck_features = base_model.predict(img)\n",
    "        \n",
    "        bottleneck_features = tf.io.serialize_tensor(bottleneck_features)\n",
    "        one_hot_label = tf.io.serialize_tensor(row.one_hot)\n",
    "                \n",
    "        writer.write(create_example_record(one_hot_label, bottleneck_features))\n",
    "        \n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print(count)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model, preprocess, input_shape = get_base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tfrecords(train_df[650000:], name = 'train_650000_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tfrecords(valid_df, name = 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    features = {\n",
    "                'one_hot_label': tf.io.FixedLenFeature((), tf.string),\n",
    "                'bottleneck_features': tf.io.FixedLenFeature((), tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    bottleneck_features = tf.io.parse_tensor(example['bottleneck_features'], out_type = tf.float32)\n",
    "    bottleneck_features = tf.reshape(bottleneck_features, [-1])\n",
    "    one_hot_label = tf.io.parse_tensor(example['one_hot_label'], out_type = tf.int64)\n",
    "    \n",
    "    bottleneck_features.set_shape([1920])\n",
    "    one_hot_label.set_shape([6])\n",
    "    \n",
    "    return bottleneck_features, one_hot_label\n",
    "\n",
    "def create_dataset(record_dir, batch_size = 32):\n",
    "    #train_dataset = tf.data.Dataset.list_files(record_dir + \"train*.tfrecords\")\n",
    "    filenames = tf.io.gfile.glob(record_dir + \"train*.tfrecords\")\n",
    "    train_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    train_dataset = train_dataset.map(read_tfrecord).repeat().shuffle(10000).batch(batch_size)\n",
    "    \n",
    "    #val_dataset = tf.data.Dataset.list_files(record_dir + \"valid*.tfrecords\")\n",
    "    val_filenames = tf.io.gfile.glob(record_dir + \"valid*.tfrecords\")\n",
    "    val_dataset = tf.data.TFRecordDataset(val_filenames)\n",
    "    val_dataset = val_dataset.map(read_tfrecord).batch(batch_size)\n",
    "    \n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create class weights to use in the loss function. The classes with not enough representation will get higher weight. So the model will pay more attention to mistakes in these classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>any</th>\n",
       "      <th>ID</th>\n",
       "      <th>class</th>\n",
       "      <th>one_hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_327e33972</td>\n",
       "      <td>x</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_cedd11e21</td>\n",
       "      <td>intraventricularany</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_f88929622</td>\n",
       "      <td>x</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_02595b48e</td>\n",
       "      <td>x</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_769385a56</td>\n",
       "      <td>intraventricularany</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epidural  intraparenchymal  intraventricular  subarachnoid  subdural  any  \\\n",
       "0         0                 0                 0             0         0    0   \n",
       "1         0                 0                 1             0         0    1   \n",
       "2         0                 0                 0             0         0    0   \n",
       "3         0                 0                 0             0         0    0   \n",
       "4         0                 0                 1             0         0    1   \n",
       "\n",
       "             ID                class             one_hot  \n",
       "0  ID_327e33972                    x  [0, 0, 0, 0, 0, 0]  \n",
       "1  ID_cedd11e21  intraventricularany  [0, 0, 1, 0, 0, 1]  \n",
       "2  ID_f88929622                    x  [0, 0, 0, 0, 0, 0]  \n",
       "3  ID_02595b48e                    x  [0, 0, 0, 0, 0, 0]  \n",
       "4  ID_769385a56  intraventricularany  [0, 0, 1, 0, 0, 1]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(ground_truth)\n",
    "class_weights = [length/(8*ground_truth[label].sum()) for label in CLASS_NAMES[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights += [sum(class_weights)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29.9206279809221,\n",
       " 2.605359516030788,\n",
       " 3.5909320740316732,\n",
       " 2.6377119831814997,\n",
       " 1.9950891532035788,\n",
       " 40.74972070736963]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(2048, input_shape = (1920,), activation = 'relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(6, activation = 'sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, class_weights, **kwargs):\n",
    "        self.class_weights = class_weights\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.expand_dims(y_true, -1)\n",
    "        y_pred = tf.expand_dims(y_pred, -1)\n",
    "\n",
    "        loss_per_class = tf.keras.losses.BinaryCrossentropy(reduction = tf.keras.losses.Reduction.NONE)\n",
    "        \n",
    "        weighted_average = tf.reduce_sum(loss_per_class(y_true, y_pred) * self.class_weights, axis = 1)/tf.reduce_sum(self.class_weights)\n",
    "\n",
    "        return tf.reduce_mean(weighted_average)\n",
    "                        \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"class_weights\": self.class_weights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_steps = len(train_df) // batch_size\n",
    "epochs = 20\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
    "                        loss = WeightedLoss(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dir = \"../input/rsnabottleneckvalid150000/\"\n",
    "train_dataset, val_dataset = create_dataset(record_dir, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 22348 steps\n",
      "Epoch 1/20\n",
      "22348/22348 [==============================] - 132s 6ms/step - loss: 0.1966 - val_loss: 0.1856\n",
      "Epoch 2/20\n",
      "22348/22348 [==============================] - 125s 6ms/step - loss: 0.1881 - val_loss: 0.1836\n",
      "Epoch 3/20\n",
      "22348/22348 [==============================] - 124s 6ms/step - loss: 0.1861 - val_loss: 0.1810\n",
      "Epoch 4/20\n",
      "22348/22348 [==============================] - 121s 5ms/step - loss: 0.1852 - val_loss: 0.1798\n",
      "Epoch 5/20\n",
      "22348/22348 [==============================] - 120s 5ms/step - loss: 0.1846 - val_loss: 0.1803\n",
      "Epoch 6/20\n",
      "22348/22348 [==============================] - 119s 5ms/step - loss: 0.1842 - val_loss: 0.1804\n",
      "Epoch 7/20\n",
      "22348/22348 [==============================] - 120s 5ms/step - loss: 0.1835 - val_loss: 0.1798\n",
      "Epoch 8/20\n",
      "22348/22348 [==============================] - 120s 5ms/step - loss: 0.1835 - val_loss: 0.1789\n",
      "Epoch 9/20\n",
      "22348/22348 [==============================] - 120s 5ms/step - loss: 0.1830 - val_loss: 0.1791\n",
      "Epoch 10/20\n",
      "22348/22348 [==============================] - 119s 5ms/step - loss: 0.1828 - val_loss: 0.1803\n",
      "Epoch 11/20\n",
      "22348/22348 [==============================] - 120s 5ms/step - loss: 0.1824 - val_loss: 0.1776\n",
      "Epoch 12/20\n",
      "22348/22348 [==============================] - 121s 5ms/step - loss: 0.1821 - val_loss: 0.1773\n",
      "Epoch 13/20\n",
      "22348/22348 [==============================] - 120s 5ms/step - loss: 0.1820 - val_loss: 0.1777\n",
      "Epoch 14/20\n",
      "22348/22348 [==============================] - 120s 5ms/step - loss: 0.1818 - val_loss: 0.1775\n",
      "Epoch 15/20\n",
      "22348/22348 [==============================] - 119s 5ms/step - loss: 0.1812 - val_loss: 0.1818\n",
      "Epoch 16/20\n",
      "22348/22348 [==============================] - 121s 5ms/step - loss: 0.1815 - val_loss: 0.1768\n",
      "Epoch 17/20\n",
      "22348/22348 [==============================] - 121s 5ms/step - loss: 0.1814 - val_loss: 0.1776\n",
      "Epoch 18/20\n",
      "22348/22348 [==============================] - 120s 5ms/step - loss: 0.1813 - val_loss: 0.1769\n",
      "Epoch 19/20\n",
      "22348/22348 [==============================] - 120s 5ms/step - loss: 0.1811 - val_loss: 0.1789\n",
      "Epoch 20/20\n",
      "22348/22348 [==============================] - 120s 5ms/step - loss: 0.1807 - val_loss: 0.1778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0750422d30>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                 factor=0.9, \n",
    "                                                 patience=2, \n",
    "                                                 min_delta=0.0001, \n",
    "                                                 cooldown=0, \n",
    "                                                 min_lr=0.0001)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = 'model_at_epoch_{epoch:02d}.hdf5', \n",
    "                                                monitor='val_loss', \n",
    "                                                save_best_only=True)\n",
    "\n",
    "model.fit(train_dataset, \n",
    "          epochs = epochs, \n",
    "          steps_per_epoch = num_steps,\n",
    "          validation_data = val_dataset,\n",
    "          callbacks = [scheduler, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(DATA_DIR + 'stage_2_sample_submission.csv', index_col = 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121232 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/121232 [00:00<9:14:00,  3.65it/s]\u001b[A\n",
      "  0%|          | 2/121232 [00:00<7:56:57,  4.24it/s]\u001b[A\n",
      "  0%|          | 3/121232 [00:00<7:01:27,  4.79it/s]\u001b[A\n",
      "  0%|          | 4/121232 [00:00<6:20:41,  5.31it/s]\u001b[A\n",
      "  0%|          | 5/121232 [00:00<5:52:45,  5.73it/s]\u001b[A\n",
      "  0%|          | 6/121232 [00:00<5:32:40,  6.07it/s]\u001b[A\n",
      "  0%|          | 7/121232 [00:01<5:20:46,  6.30it/s]\u001b[A\n",
      "  0%|          | 8/121232 [00:01<5:11:50,  6.48it/s]\u001b[A\n",
      "  0%|          | 9/121232 [00:01<5:05:31,  6.61it/s]\u001b[A\n",
      "  0%|          | 10/121232 [00:01<5:01:36,  6.70it/s]\u001b[A\n",
      "  0%|          | 11/121232 [00:01<5:03:00,  6.67it/s]\u001b[A\n",
      "  0%|          | 12/121232 [00:01<4:57:33,  6.79it/s]\u001b[A\n",
      "  0%|          | 13/121232 [00:02<5:26:25,  6.19it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-b27feeaa0dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbottleneck_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \"\"\"\n\u001b[1;32m    821\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \"\"\"\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for img_id in test_images:\n",
    "    img_path = test_img_dir + img_id\n",
    "    img = create_window_channels(img_path)\n",
    "    \n",
    "    img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "\n",
    "    img = preprocess(img)\n",
    "    bottleneck_features = base_model.predict(img)\n",
    "    \n",
    "    prediction = model.predict(bottleneck_features)\n",
    "    id_type_names = [img_id.split('.')[0] + '_' + cls for cls in CLASS_NAMES]\n",
    "    submission_df.loc[id_type_names, 'Label'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID_0fbf6a978_epidural</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_0fbf6a978_intraparenchymal</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_0fbf6a978_intraventricular</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_0fbf6a978_subarachnoid</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_0fbf6a978_subdural</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_0fbf6a978_any</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_d62ec3412_epidural</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_d62ec3412_intraparenchymal</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_d62ec3412_intraventricular</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_d62ec3412_subarachnoid</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Label\n",
       "ID                                  \n",
       "ID_0fbf6a978_epidural            0.5\n",
       "ID_0fbf6a978_intraparenchymal    0.5\n",
       "ID_0fbf6a978_intraventricular    0.5\n",
       "ID_0fbf6a978_subarachnoid        0.5\n",
       "ID_0fbf6a978_subdural            0.5\n",
       "ID_0fbf6a978_any                 0.5\n",
       "ID_d62ec3412_epidural            0.5\n",
       "ID_d62ec3412_intraparenchymal    0.5\n",
       "ID_d62ec3412_intraventricular    0.5\n",
       "ID_d62ec3412_subarachnoid        0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rsna_env] *",
   "language": "python",
   "name": "conda-env-rsna_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
